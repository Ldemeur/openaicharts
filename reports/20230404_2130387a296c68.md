# Report
File: *Symptom2Disease.csv*

Load the data into a pandas DataFrame and check the first few rows

```python
import pandas as pd

file_path = 'Symptom2Disease.csv'
df = pd.read_csv(file_path)
print(df.head())
```

```json
output:
   Unnamed: 0      label                                               text
0           0  Psoriasis  I have been experiencing a skin rash on my arm...
1           1  Psoriasis  My skin has been peeling, especially on my kne...
2           2  Psoriasis  I have been experiencing joint pain in my fing...
3           3  Psoriasis  There is a silver like dusting on my skin, esp...
4           4  Psoriasis  My nails have small dents or pits in them, and...

```

Drop the unnecessary 'Unnamed: 0' column and print statistics of the dataset

```python
df = df.drop(columns=['Unnamed: 0'])
print(df.describe(include='all'))
```

```json
output:
            label                                               text
count        1200                                               1200
unique         24                                               1153
top     Psoriasis  I've been feeling extremely scratchy, sick, an...
freq           50                                                  4

```

Calculate frequencies of all unique diseases

```python
disease_counts = df['label'].value_counts()
print(disease_counts)
```

```json
output:
label
Psoriasis                          50
Varicose Veins                     50
peptic ulcer disease               50
drug reaction                      50
gastroesophageal reflux disease    50
allergy                            50
urinary tract infection            50
Malaria                            50
Jaundice                           50
Cervical spondylosis               50
Migraine                           50
Hypertension                       50
Bronchial Asthma                   50
Acne                               50
Arthritis                          50
Dimorphic Hemorr
```

Visualize the frequencies of unique diseases

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.bar(disease_counts.index, disease_counts.values)
plt.xticks(rotation=90)
plt.title('Frequency of Unique Diseases')
plt.ylabel('Frequency')
plt.show()
```

```json
Got exception: $No module named 'matplotlib'
```

As matplotlib is not available, let's use command line for visualization

```python
print('Frequency of Unique Diseases:')
for index, value in disease_counts.iteritems():
  print(f'{index}: {value}')
```

```json
Got exception: $'Series' object has no attribute 'iteritems'output:
Frequency of Unique Diseases:

```

Fix the error and print disease frequencies again

```python
print('Frequency of Unique Diseases:')
for index, value in disease_counts.items():
  print(f'{index}: {value}')
```

```json
output:
Frequency of Unique Diseases:
Psoriasis: 50
Varicose Veins: 50
peptic ulcer disease: 50
drug reaction: 50
gastroesophageal reflux disease: 50
allergy: 50
urinary tract infection: 50
Malaria: 50
Jaundice: 50
Cervical spondylosis: 50
Migraine: 50
Hypertension: 50
Bronchial Asthma: 50
Acne: 50
Arthritis: 50
Dimorphic Hemorrhoids: 50
Pneumonia: 50
Common Cold: 50
Fungal infection: 50
Dengue: 50
Impetigo: 50
Chicken pox: 50
Typhoid: 50
diabetes: 50

```

Tokenize the text description and get the frequency count of most common words

```python
from collections import Counter
import re

word_counts = Counter()
for description in df['text']:
  words = re.findall(r'\w+', description.lower())
  word_counts.update(words)

most_common_words = word_counts.most_common(15)
print('Most Common Words:', most_common_words)
```

```json
output:
Most Common Words: [('and', 2609), ('i', 2463), ('my', 1859), ('a', 1266), ('been', 1102), ('have', 1059), ('ve', 670), ('of', 533), ('to', 518), ('the', 515), ('is', 505), ('in', 435), ('has', 432), ('also', 418), ('it', 416)]

```

Remove stopwords and print the most common words without stopwords

```python
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))
filtered_word_counts = {word: count for word, count in word_counts.items() if word not in stop_words}

filtered_most_common_words = sorted(filtered_word_counts.items(), key=lambda x: x[1], reverse=True)[:15]

print('Most Common Words Without Stopwords:', filtered_most_common_words)
```

```json
Got exception: $
**********************************************************************
  Resource [93mstopwords[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('stopwords')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mcorpora/stopwords[0m

  Searched in:
    - '/home/fela/nltk_data'
    - '/home/fela/Dev/python/gpt-4-hackathon/venv/nltk_data'
    - '/home/fela/Dev/python/gpt-4-hackathon/venv/share/nltk_data'
    - '/home/fela/Dev/python/gpt-4-hackathon/venv/lib/nltk_data'
    -
```

Since manual_stopwords list is too long, let's create a function that compares word frequencies

```python
def compare_word_frequencies(word_counts, stop_words):
  filtered_word_counts = {word: count for word, count in word_counts.items() if word not in stop_words}
  filtered_most_common_words = sorted(filtered_word_counts.items(), key=lambda x: x[1], reverse=True)[:15]
  return filtered_most_common_words

manual_stopwords = {'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'have', 'i', 'in', 'is', 'it', 'my', 'of', 'on', 'or', 'that', 'the', 'this', 'to', 'was', 'were', 'with'}
most_common_words_without_stopwords = compare_word_frequencies(word_counts, manual_stopwords)
print('Most Common Words Without Stopwords:', most_common_words_without_stopwords)
```

```json
output:
Most Common Words Without Stopwords: [('been', 1102), ('ve', 670), ('also', 418), ('skin', 384), ('lot', 353), ('really', 331), ('pain', 307), ('m', 258), ('fever', 243), ('me', 224), ('feel', 218), ('feeling', 217), ('experiencing', 208), ('high', 205), ('neck', 179)]

```

Analyze correlations between word frequencies and diseases

```python
from collections import defaultdict

disease_to_word_counts = defaultdict(Counter)
for index, row in df.iterrows():
  words = re.findall(r'\w+', row['text'].lower())
  words = [word for word in words if word not in manual_stopwords]
  disease_to_word_counts[row['label']].update(words)

# Calculate correlations
word_disease_freqs = {}
for disease, word_counts in disease_to_word_counts.items():
  word_disease_freqs[disease] = word_counts.most_common(10)
print('Word Frequencies per Disease:')
for disease, freqs in word_disease_freqs.items():
  print(f'{disease}: {freqs}')
```

```json
output:
Word Frequencies per Disease:
Psoriasis: [('skin', 56), ('pain', 18), ('nails', 18), ('rash', 15), ('there', 15), ('peeling', 14), ('am', 14), ('arms', 13), ('joints', 13), ('back', 13)]
Varicose Veins: [('legs', 40), ('causing', 23), ('veins', 22), ('calves', 20), ('me', 18), ('am', 17), ('lot', 16), ('time', 16), ('skin', 16), ('cramps', 16)]
Typhoid: [('been', 60), ('pain', 31), ('really', 28), ('ve', 28), ('constipation', 24), ('fever', 24), ('am', 21), ('stomach', 19), ('t', 18), ('lot', 18)]
Chicken pox: [('s', 27), ('red', 27), ('fever', 24), ('me', 23), ('spots', 21), ('t', 20)
```

Let's create a function to calculate the Jaccard similarity between diseases

```python
def jaccard_similarity(disease1, disease2):
  words1 = set([word for word, _ in word_disease_freqs[disease1]])
  words2 = set([word for word, _ in word_disease_freqs[disease2]])
  intersection = words1.intersection(words2)
  union = words1.union(words2)
  return len(intersection) / len(union)

# Calculate the Jaccard similarities for all disease pairs
jaccard_similarities = {}
unique_diseases = list(disease_counts.index)
for i in range(len(unique_diseases)):
  for j in range(i + 1, len(unique_diseases)):
    disease1 = unique_diseases[i]
    disease2 = unique_diseases[j]
    similarity = jaccard_similarity(disease1, disease2)
    jaccard_similarities[(disease1, disease2)] = similarity

# Print the 10 most similar disease pairs
sorted_similarities = sorted(jaccard_similarities.items(), key=lambda x: x[1], reverse=True)[:10]
print('Top 10 Most Similar Disease Pairs:')
for (disease1, disease2), similarity in sorted_similarities:
  print(f'{disease1} - {disease2}: {similarity:.2f}')
```

```json
output:
Top 10 Most Similar Disease Pairs:
Malaria - Bronchial Asthma: 0.43
Pneumonia - Common Cold: 0.43
Common Cold - Typhoid: 0.33
allergy - diabetes: 0.25
Malaria - Jaundice: 0.25
Malaria - Hypertension: 0.25
Malaria - Typhoid: 0.25
Jaundice - Bronchial Asthma: 0.25
Jaundice - Fungal infection: 0.25
Jaundice - Typhoid: 0.25

```

Analyze the most common symptoms of the most similar disease pairs

```python
print('Most Common Symptoms for Similar Disease Pairs:')
for (disease1, disease2), _ in sorted_similarities:
  print(f'{disease1}: {word_disease_freqs[disease1]}')
  print(f'{disease2}: {word_disease_freqs[disease2]}')
  print()
```

```json
output:
Most Common Symptoms for Similar Disease Pairs:
Malaria: [('been', 75), ('ve', 66), ('nausea', 53), ('also', 52), ('lot', 51), ('chills', 50), ('headache', 50), ('high', 48), ('fever', 39), ('perspiring', 36)]
Bronchial Asthma: [('been', 95), ('ve', 73), ('cough', 55), ('fever', 47), ('lot', 43), ('high', 40), ('feeling', 29), ('breathing', 28), ('m', 27), ('also', 25)]

Pneumonia: [('m', 78), ('ve', 48), ('lot', 44), ('been', 42), ('heart', 41), ('phlegm', 33), ('coughing', 32), ('chest', 32), ('up', 31), ('really', 30)]
Common Cold: [('ve', 62), ('been', 59), ('lot', 44), ('really', 
```

Overall summary of findings

```python
print('==== Summary of Findings ====')
print('\n- There are 24 unique diseases in the dataset with 50 occurrences each.')
print('\n- The most common words found in the descriptions (excluding common stopwords) are:', most_common_words_without_stopwords)
print('\n- Some pairs of diseases have similar symptoms:')
for (disease1, disease2), similarity in sorted_similarities:
  print(f'  - {disease1} and {disease2} (Jaccard similarity: {similarity:.2f})')

print('\n- The most common symptoms for each disease are:')
for disease, freqs in word_disease_freqs.items():
  print(f'  - {disease}:', [f'{word} ({count})' for word, count in freqs])
print('\nKeep in mind that similarities could be due to the dataset being limited and not covering all possible symptoms.')
```

```json
output:
==== Summary of Findings ====

- There are 24 unique diseases in the dataset with 50 occurrences each.

- The most common words found in the descriptions (excluding common stopwords) are: [('been', 1102), ('ve', 670), ('also', 418), ('skin', 384), ('lot', 353), ('really', 331), ('pain', 307), ('m', 258), ('fever', 243), ('me', 224), ('feel', 218), ('feeling', 217), ('experiencing', 208), ('high', 205), ('neck', 179)]

- Some pairs of diseases have similar symptoms:
  - Malaria and Bronchial Asthma (Jaccard similarity: 0.43)
  - Pneumonia and Common Cold (Jaccard similarity: 0.43)
  - C
```

# Summary
## Summary of Findings

- The dataset contains 24 unique diseases, each with 50 occurrences.
- After removing common stopwords, the most common words found in the descriptions are: `'been', 've', 'also', 'skin', 'lot', 'really', 'pain', 'm', 'fever', 'me', 'feel', 'feeling', 'experiencing', 'high', 'neck'`.
- Some pairs of diseases have similar symptoms based on the Jaccard similarity:
  - Malaria and Bronchial Asthma (0.43)
  - Pneumonia and Common Cold (0.43)
  - Common Cold and Typhoid (0.33)
- The most common symptoms for each disease have been identified, but it is important to note that the similarities could be due to the dataset being limited and not covering all possible symptoms.

Overall, this analysis provides a general understanding of the dataset and identifies common symptoms and similarities between diseases. Further analysis could be performed to understand the distinction between diseases and improve diagnosis accuracy for future applications.